{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "578b3ec7",
   "metadata": {},
   "source": [
    "Patricia Trie Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595232e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e9b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatriciaTrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.is_end_of_word = False\n",
    "\n",
    "class PatriciaTrie:\n",
    "    def __init__(self):\n",
    "        self.root = PatriciaTrieNode()\n",
    "\n",
    "    def insert(self, word):\n",
    "        node = self.root\n",
    "        while word:\n",
    "            for key in node.children.keys():\n",
    "                common_prefix = self._common_prefix(word, key)\n",
    "                if common_prefix:\n",
    "                    if common_prefix == key:\n",
    "                        node = node.children[key]\n",
    "                        word = word[len(common_prefix):]\n",
    "                    else:\n",
    "                        existing_node = node.children.pop(key)\n",
    "                        new_node = PatriciaTrieNode()\n",
    "                        new_node.children[key[len(common_prefix):]] = existing_node\n",
    "                        node.children[common_prefix] = new_node\n",
    "                        node = new_node\n",
    "                        word = word[len(common_prefix):]\n",
    "                        break\n",
    "            else:\n",
    "                node.children[word] = PatriciaTrieNode()\n",
    "                node = node.children[word]\n",
    "                word = ''\n",
    "        node.is_end_of_word = True\n",
    "\n",
    "    def count_frequency(self, sequence, pattern):\n",
    "        count = 0\n",
    "        pattern_len = len(pattern)\n",
    "        for i in range(len(sequence) - pattern_len + 1):\n",
    "            if sequence[i:i + pattern_len] == pattern:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    def _common_prefix(self, str1, str2):\n",
    "        min_len = min(len(str1), len(str2))\n",
    "        for i in range(min_len):\n",
    "            if str1[i] != str2[i]:\n",
    "                return str1[:i]\n",
    "        return str1[:min_len]\n",
    "\n",
    "def count_pattern_in_exons_with_patricia_trie(sequence, exon_ranges, pattern):\n",
    "    trie = PatriciaTrie()\n",
    "    total_count = 0\n",
    "    for start, end in exon_ranges:\n",
    "        segment = sequence[start-1:end]  # Adjusting for 0-based indexing\n",
    "        total_count += trie.count_frequency(segment, pattern)\n",
    "    return total_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54585c25",
   "metadata": {},
   "source": [
    " Trie Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795479e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.is_end_of_word = False\n",
    "        self.frequency = 0\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "\n",
    "    def insert(self, word):\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = TrieNode()\n",
    "            node = node.children[char]\n",
    "        node.is_end_of_word = True\n",
    "        node.frequency += 1\n",
    "\n",
    "    def search(self, word):\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                return 0\n",
    "            node = node.children[char]\n",
    "        return node.frequency if node.is_end_of_word else 0\n",
    "\n",
    "def count_pattern_in_exons(sequence, exon_ranges, pattern):\n",
    "    trie = Trie()\n",
    "    pattern_len = len(pattern)\n",
    "    for start, end in exon_ranges:\n",
    "        segment = sequence[start-1:end]  # Adjusting for 0-based indexing\n",
    "        for i in range(len(segment) - pattern_len + 1):\n",
    "            substring = segment[i:i + pattern_len]\n",
    "            trie.insert(substring)\n",
    "    return trie.search(pattern)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c06351",
   "metadata": {},
   "source": [
    "BWT Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ceffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bwt_transform(sequence):\n",
    "    sequence = sequence + \"$\"  # Add end of string marker\n",
    "    table = sorted(sequence[i:] + sequence[:i] for i in range(len(sequence)))\n",
    "    return ''.join(row[-1] for row in table)\n",
    "\n",
    "def bwt_search(bwt, pattern):\n",
    "    suffix_array = sorted(range(len(bwt)), key=lambda i: bwt[i:])\n",
    "    first_col = ''.join(sorted(bwt))\n",
    "\n",
    "    counts = {}\n",
    "    for char in bwt:\n",
    "        if char in counts:\n",
    "            counts[char] += 1\n",
    "        else:\n",
    "            counts[char] = 1\n",
    "\n",
    "    first_occurrence = {}\n",
    "    total = 0\n",
    "    for char in sorted(counts.keys()):\n",
    "        first_occurrence[char] = total\n",
    "        total += counts[char]\n",
    "\n",
    "    l, r = 0, len(bwt) - 1\n",
    "    for char in reversed(pattern):\n",
    "        if char in first_occurrence:\n",
    "            l = first_occurrence[char] + bwt[:l].count(char)\n",
    "            r = first_occurrence[char] + bwt[:r+1].count(char) - 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    return r - l + 1\n",
    "\n",
    "def count_pattern_in_exons_with_bwt(sequence, exon_ranges, pattern):\n",
    "    total_count = 0\n",
    "    for start, end in exon_ranges:\n",
    "        segment = sequence[start-1:end]  # Adjusting for 0-based indexing\n",
    "        bwt = bwt_transform(segment)\n",
    "        total_count += bwt_search(bwt, pattern)\n",
    "    return total_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c5bf16",
   "metadata": {},
   "source": [
    "Bloom Filter Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "class CountingBloomFilter:\n",
    "    def __init__(self, size, num_hashes):\n",
    "        self.size = size\n",
    "        self.num_hashes = num_hashes\n",
    "        self.bloom = [0] * size\n",
    "\n",
    "    def _hashes(self, item):\n",
    "        hashes = []\n",
    "        for i in range(self.num_hashes):\n",
    "            hash_result = int(hashlib.md5((item + str(i)).encode()).hexdigest(), 16)\n",
    "            hashes.append(hash_result % self.size)\n",
    "        return hashes\n",
    "\n",
    "    def add(self, item):\n",
    "        for hash_val in self._hashes(item):\n",
    "            self.bloom[hash_val] += 1\n",
    "\n",
    "    def count(self, item):\n",
    "        return min(self.bloom[hash_val] for hash_val in self._hashes(item))\n",
    "\n",
    "def find_pattern_frequency(sequence, pattern, bloom_size, num_hashes):\n",
    "    bloom_filter = CountingBloomFilter(bloom_size, num_hashes)\n",
    "    kmer_size = len(pattern)\n",
    "    for i in range(len(sequence) - kmer_size + 1):\n",
    "        kmer = sequence[i:i+kmer_size]\n",
    "        bloom_filter.add(kmer)\n",
    "    return bloom_filter.count(pattern)\n",
    "\n",
    "def count_pattern_in_exons_with_bloom_filter(sequence, exon_ranges, pattern, bloom_size, num_hashes):\n",
    "    total_count = 0\n",
    "    for start, end in exon_ranges:\n",
    "        segment = sequence[start-1:end]  # Adjusting for 0-based indexing\n",
    "        total_count += find_pattern_frequency(segment, pattern, bloom_size, num_hashes)\n",
    "    return total_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01342c27",
   "metadata": {},
   "source": [
    "Suffix Array Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_suffix_array(text):\n",
    "    suffixes = [(text[i:], i) for i in range(len(text))]\n",
    "    suffixes.sort()\n",
    "    suffix_array = [suffix[1] for suffix in suffixes]\n",
    "    return suffix_array\n",
    "\n",
    "def suffix_array_search(sequence, pattern, suffix_array):\n",
    "    left = 0\n",
    "    right = len(suffix_array) - 1\n",
    "    pattern_length = len(pattern)\n",
    "    count = 0\n",
    "\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        start_index = suffix_array[mid]\n",
    "        substring = sequence[start_index:start_index + pattern_length]\n",
    "\n",
    "        if pattern == substring:\n",
    "            count += 1\n",
    "            l, r = mid - 1, mid + 1\n",
    "            while l >= 0 and sequence[suffix_array[l]:suffix_array[l] + pattern_length] == pattern:\n",
    "                count += 1\n",
    "                l -= 1\n",
    "            while r < len(suffix_array) and sequence[suffix_array[r]:suffix_array[r] + pattern_length] == pattern:\n",
    "                count += 1\n",
    "                r += 1\n",
    "            break\n",
    "        elif pattern < substring:\n",
    "            right = mid - 1\n",
    "        else:\n",
    "            left = mid + 1\n",
    "\n",
    "    return count\n",
    "\n",
    "def count_pattern_in_exons_with_suffix_array(sequence, exon_ranges, pattern):\n",
    "    total_count = 0\n",
    "    for start, end in exon_ranges:\n",
    "        segment = sequence[start-1:end]  # Adjusting for 0-based indexing\n",
    "        suffix_array = build_suffix_array(segment)\n",
    "        total_count += suffix_array_search(segment, pattern, suffix_array)\n",
    "    return total_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ea6346",
   "metadata": {},
   "source": [
    "Wavelet Tree Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa27e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletTree:\n",
    "    def __init__(self, data, alphabet=None):\n",
    "        if alphabet is None:\n",
    "            alphabet = sorted(set(data))\n",
    "        self.alphabet = alphabet\n",
    "        self.mid = len(alphabet) // 2\n",
    "        self.left = self.right = None\n",
    "        self.bit_vector = []\n",
    "\n",
    "        if len(data) == 0 or len(alphabet) <= 1:  # Base case for recursion\n",
    "            return\n",
    "\n",
    "        left_alphabet = alphabet[:self.mid]\n",
    "        right_alphabet = alphabet[self.mid:]\n",
    "\n",
    "        left_data = []\n",
    "        right_data = []\n",
    "\n",
    "        for char in data:\n",
    "            if char in left_alphabet:\n",
    "                self.bit_vector.append(0)\n",
    "                left_data.append(char)\n",
    "            else:\n",
    "                self.bit_vector.append(1)\n",
    "                right_data.append(char)\n",
    "\n",
    "        if left_data:\n",
    "            self.left = WaveletTree(left_data, left_alphabet)\n",
    "        if right_data:\n",
    "            self.right = WaveletTree(right_data, right_alphabet)\n",
    "\n",
    "    def rank(self, char, index):\n",
    "        if len(self.alphabet) <= 1:\n",
    "            return index + 1\n",
    "\n",
    "        if char in self.alphabet[:self.mid]:\n",
    "            return self.left.rank(char, self.bit_vector[:index + 1].count(0) - 1)\n",
    "        else:\n",
    "            return self.right.rank(char, self.bit_vector[:index + 1].count(1) - 1)\n",
    "\n",
    "    def range_query(self, char, start, end):\n",
    "        return self.rank(char, end) - self.rank(char, start - 1)\n",
    "\n",
    "def wavelet_tree_search(sequence, pattern):\n",
    "    wavelet_tree = WaveletTree(sequence)\n",
    "    count = 0\n",
    "    for i in range(len(sequence) - len(pattern) + 1):\n",
    "        if all(wavelet_tree.range_query(pattern[j], i + j, i + j) > 0 for j in range(len(pattern))):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def count_pattern_in_exons_with_wavelet_tree(sequence, exon_ranges, pattern):\n",
    "    total_count = 0\n",
    "    for start, end in exon_ranges:\n",
    "        segment = sequence[start-1:end]  # Adjusting for 0-based indexing\n",
    "        total_count += wavelet_tree_search(segment, pattern)\n",
    "    return total_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca52c438",
   "metadata": {},
   "source": [
    "DFA Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4248bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFA Implementation\n",
    "class DFA:\n",
    "    def __init__(self, pattern):\n",
    "        self.pattern = pattern\n",
    "        self.states = len(pattern) + 1\n",
    "        self.alphabet = set(pattern)\n",
    "        self.transition_table = self.build_transition_table()\n",
    "\n",
    "    def build_transition_table(self):\n",
    "        transition_table = {}\n",
    "        for state in range(self.states):\n",
    "            for char in self.alphabet:\n",
    "                next_state = min(self.states - 1, state + 1)\n",
    "                while next_state > 0 and self.pattern[next_state - 1] != char:\n",
    "                    next_state -= 1\n",
    "                transition_table[(state, char)] = next_state\n",
    "        return transition_table\n",
    "\n",
    "    def search(self, text):\n",
    "        state = 0\n",
    "        occurrences = []\n",
    "        for i, char in enumerate(text):\n",
    "            if (state, char) in self.transition_table:\n",
    "                state = self.transition_table[(state, char)]\n",
    "            else:\n",
    "                state = 0\n",
    "\n",
    "            if state == self.states - 1:\n",
    "                occurrences.append(i - len(self.pattern) + 1)\n",
    "                state = 0  # Reset state after finding a match\n",
    "        return occurrences\n",
    "\n",
    "def count_pattern_in_exons_with_dfa(sequence, exon_ranges, pattern):\n",
    "    dfa = DFA(pattern)\n",
    "    total_count = 0\n",
    "    for start, end in exon_ranges:\n",
    "        segment = sequence[start-1:end]  # Adjusting for 0-based indexing\n",
    "        total_count += len(dfa.search(segment))\n",
    "    return total_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd72ea",
   "metadata": {},
   "source": [
    "KMP Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57427dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmp_preprocess(pattern):\n",
    "    lps = [0] * len(pattern)\n",
    "    length = 0\n",
    "    i = 1\n",
    "\n",
    "    while i < len(pattern):\n",
    "        if pattern[i] == pattern[length]:\n",
    "            length += 1\n",
    "            lps[i] = length\n",
    "            i += 1\n",
    "        else:\n",
    "            if length != 0:\n",
    "                length = lps[length - 1]\n",
    "            else:\n",
    "                lps[i] = 0\n",
    "                i += 1\n",
    "\n",
    "    return lps\n",
    "\n",
    "def kmp_search_in_ranges(sequence, pattern, ranges):\n",
    "    lps = kmp_preprocess(pattern)\n",
    "    positions = []\n",
    "\n",
    "    for start, end in ranges:\n",
    "        i = start  # index for sequence\n",
    "        j = 0  # index for pattern\n",
    "        while i < end:\n",
    "            if pattern[j] == sequence[i]:\n",
    "                i += 1\n",
    "                j += 1\n",
    "\n",
    "            if j == len(pattern):\n",
    "                positions.append(i - j)\n",
    "                j = lps[j - 1]\n",
    "            elif i < end and pattern[j] != sequence[i]:\n",
    "                if j != 0:\n",
    "                    j = lps[j - 1]\n",
    "                else:\n",
    "                    i += 1\n",
    "\n",
    "    return positions\n",
    "\n",
    "def count_pattern_in_exons_with_kmp(sequence, exon_ranges, pattern):\n",
    "    positions = kmp_search_in_ranges(sequence, pattern, exon_ranges)\n",
    "    return len(positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9eab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENSCAN output parsing\n",
    "def parse_genscan_output(genscan_output):\n",
    "    pattern = re.compile(r'\\s+\\d+\\.\\d+\\s+\\w+\\s+[+-]\\s+(\\d+)\\s+(\\d+)\\s+\\d+\\s+\\d\\s+\\d\\s+(\\d*)\\s+(\\d*)\\s+(\\d*)\\s+\\d*\\.\\d*\\s+\\d*\\.\\d*')\n",
    "    matches = pattern.findall(genscan_output)\n",
    "    filtered_matches = [match for match in matches if all(match[2:])]\n",
    "    columns = ['Begin', 'End', 'Ph', 'I/Ac', 'Do/T']\n",
    "    data = pd.DataFrame(filtered_matches, columns=columns)\n",
    "    data[['Begin', 'End']] = data[['Begin', 'End']].apply(pd.to_numeric, errors='coerce')\n",
    "    exon_ranges = list(zip(data['Begin'], data['End']))\n",
    "    return exon_ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fecce06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GENSCAN output(example output of exon ranges data from genscan server)\n",
    "genscan_output = \"\"\"\n",
    "Gn.Ex Type S .Begin ...End .Len Fr Ph I/Ac Do/T CodRg P.... Tscr..\n",
    "\n",
    "----- ---- - ------ ------ ---- -- -- ---- ---- ----- ----- ------\n",
    "\n",
    "\n",
    "\n",
    " 1.01 Sngl +   1127   3889 2763  1  0   60   48  2946 0.998 280.71\n",
    "\n",
    " 1.02 PlyA +   4392   4397    6                               1.05\n",
    "\n",
    "\n",
    "\n",
    " 2.03 PlyA -   4549   4544    6                               1.05\n",
    "\n",
    " 2.02 Term -   5235   5080  156  0  0   44   43   145 0.785   3.53\n",
    "\n",
    " 2.01 Intr -   7099   6961  139  0  1   86   81    66 0.905   6.17\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "fasta_file_path =r\"C:\\Users\\yaaju\\Downloads\\mrnas_by_gene\\AR\\NM_000044.6.fna\"\n",
    "pattern=\"CAG\"\n",
    "def load_fasta(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    header = lines[0].strip()\n",
    "    sequence = ''.join(lines[1:]).replace('\\n', '')\n",
    "    return sequence\n",
    "sequence = load_fasta(fasta_file_path)\n",
    "exon_ranges=parse_genscan_output(genscan_output)\n",
    "\n",
    "\n",
    "print(exon_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b80ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fasta_file_path =r\"C:\\Users\\yaaju\\Downloads\\test_atxn1.fasta\"\n",
    "#pattern=\"CCG\"\n",
    "def load_fasta(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    header = lines[0].strip()\n",
    "    sequence = ''.join(lines[1:]).replace('\\n', '')\n",
    "    return sequence\n",
    "sequence = load_fasta(fasta_file_path)\n",
    "exon_ranges=parse_genscan_output(genscan_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(exon_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d142f23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pattern=\"TGC\" #declaring the pattern of the respective gene\n",
    "print(exon_ranges)\n",
    "\n",
    "bwt_count = count_pattern_in_exons_with_bwt(sequence, exon_ranges, pattern)\n",
    "print(f\"Count of '{pattern}' using BWT: {bwt_count}\")\n",
    "trie_count=count_pattern_in_exons(sequence, exon_ranges, pattern)\n",
    "print(f\"Count of '{pattern}' using trie: {trie_count}\")\n",
    "    # Bloom Filter\n",
    "bloom_size = 10000  # Adjust the size based on your needs\n",
    "num_hashes = 3      # Number of hash functions\n",
    "bloom_filter_count = count_pattern_in_exons_with_bloom_filter(sequence, exon_ranges, pattern, bloom_size, num_hashes)\n",
    "print(f\"Count of '{pattern}' using Bloom Filter: {bloom_filter_count}\")\n",
    "\n",
    "    # Suffix Array\n",
    "suffix_array_count = count_pattern_in_exons_with_suffix_array(sequence, exon_ranges, pattern)\n",
    "print(f\"Count of '{pattern}' using Suffix Array: {suffix_array_count}\")\n",
    "\n",
    "    # Wavelet Tree\n",
    "wavelet_tree_count = count_pattern_in_exons_with_wavelet_tree(sequence, exon_ranges, pattern)\n",
    "print(f\"Count of '{pattern}' using Wavelet Tree: {wavelet_tree_count}\")\n",
    "\n",
    "    # DFA\n",
    "dfa_count = count_pattern_in_exons_with_dfa(sequence, exon_ranges, pattern)\n",
    "print(f\"Count of '{pattern}' using DFA: {dfa_count}\")\n",
    "\n",
    "    # KMP\n",
    "kmp_count = count_pattern_in_exons_with_kmp(sequence, exon_ranges, pattern)\n",
    "print(f\"Count of '{pattern}' using KMP: {kmp_count}\")\n",
    "\n",
    "Patrici_c_trie=count_pattern_in_exons_with_patricia_trie(sequence, exon_ranges, pattern)\n",
    "print(f\"Count of '{pattern}' using patricia: {Patrici_c_trie}\")\n",
    "print(exon_ranges,bwt_count,trie_count,bloom_filter_count,suffix_array_count,wavelet_tree_count,dfa_count,kmp_count,Patrici_c_trie )\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf5c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
